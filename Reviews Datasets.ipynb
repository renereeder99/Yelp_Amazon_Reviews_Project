{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#https://colab.research.google.com/drive/1ohcvYZJ8mhhkhW2mRlBt2uGzZO4x9KWg?authuser=1#scrollTo=mSYdQxVlDgoZ for tokenize and ml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiTunyQ73aT9WBnpR9DZGw</td>\n",
       "      <td>OyoGAe7OKpv6SyGZT5g77Q</td>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I've taken a lot of spin classes over the year...</td>\n",
       "      <td>2012-01-03 15:28:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saUsX_uimxRlCVr67Z4Jig</td>\n",
       "      <td>8g_iMtfSiwikVnbP2etR0A</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
       "      <td>2014-02-05 20:30:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n",
       "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>2017-01-14 20:54:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JrIxlS1TzJ-iCu79ul40cQ</td>\n",
       "      <td>eUta8W_HdHMXPzLBBZhL1A</td>\n",
       "      <td>04UD14gamNjLY0IDYVhHJg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>I am a long term frequent customer of this est...</td>\n",
       "      <td>2015-09-23 23:10:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6AxgBCNX_PNTOxmbRSwcKQ</td>\n",
       "      <td>r3zeYsv1XFBRA4dJpL78cw</td>\n",
       "      <td>gmjsEdUsKpj9Xxu6pdjH0g</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Loved this tour! I grabbed a groupon and the p...</td>\n",
       "      <td>2015-01-03 23:21:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_ZeMknuYdlQcUqng_Im3yg</td>\n",
       "      <td>yfFzsLmaWF2d4Sr0UNbBgg</td>\n",
       "      <td>LHSTtnW3YHCeUkRDGyJOyw</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazingly amazing wings and homemade bleu chee...</td>\n",
       "      <td>2015-08-07 02:29:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZKvDG2sBvHVdF5oBNUOpAQ</td>\n",
       "      <td>wSTuiTk-sKNdcFyprzZAjg</td>\n",
       "      <td>B5XSoSG3SfvQGtKEGQ1tSQ</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This easter instead of going to Lopez Lake we ...</td>\n",
       "      <td>2016-03-30 22:46:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pUycOfUwM8vqX7KjRRhUEA</td>\n",
       "      <td>59MxRhNVhU9MYndMkz0wtw</td>\n",
       "      <td>gebiRewfieSdtt17PTW6Zg</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Had a party of 6 here for hibachi. Our waitres...</td>\n",
       "      <td>2016-07-25 07:31:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n",
       "2  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n",
       "3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n",
       "5  JrIxlS1TzJ-iCu79ul40cQ  eUta8W_HdHMXPzLBBZhL1A  04UD14gamNjLY0IDYVhHJg   \n",
       "6  6AxgBCNX_PNTOxmbRSwcKQ  r3zeYsv1XFBRA4dJpL78cw  gmjsEdUsKpj9Xxu6pdjH0g   \n",
       "7  _ZeMknuYdlQcUqng_Im3yg  yfFzsLmaWF2d4Sr0UNbBgg  LHSTtnW3YHCeUkRDGyJOyw   \n",
       "8  ZKvDG2sBvHVdF5oBNUOpAQ  wSTuiTk-sKNdcFyprzZAjg  B5XSoSG3SfvQGtKEGQ1tSQ   \n",
       "9  pUycOfUwM8vqX7KjRRhUEA  59MxRhNVhU9MYndMkz0wtw  gebiRewfieSdtt17PTW6Zg   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      3       0      0     0   \n",
       "1      5       1      0     1   \n",
       "2      3       0      0     0   \n",
       "3      5       1      0     1   \n",
       "4      4       1      0     1   \n",
       "5      1       1      2     1   \n",
       "6      5       0      2     0   \n",
       "7      5       2      0     0   \n",
       "8      3       1      1     0   \n",
       "9      3       0      0     0   \n",
       "\n",
       "                                                text                date  \n",
       "0  If you decide to eat here, just be aware it is... 2018-07-07 22:09:11  \n",
       "1  I've taken a lot of spin classes over the year... 2012-01-03 15:28:18  \n",
       "2  Family diner. Had the buffet. Eclectic assortm... 2014-02-05 20:30:30  \n",
       "3  Wow!  Yummy, different,  delicious.   Our favo... 2015-01-04 00:01:03  \n",
       "4  Cute interior and owner (?) gave us tour of up... 2017-01-14 20:54:15  \n",
       "5  I am a long term frequent customer of this est... 2015-09-23 23:10:31  \n",
       "6  Loved this tour! I grabbed a groupon and the p... 2015-01-03 23:21:18  \n",
       "7  Amazingly amazing wings and homemade bleu chee... 2015-08-07 02:29:16  \n",
       "8  This easter instead of going to Lopez Lake we ... 2016-03-30 22:46:33  \n",
       "9  Had a party of 6 here for hibachi. Our waitres... 2016-07-25 07:31:06  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_lines_to_read = 300000\n",
    "\n",
    "yelp_reviews = pd.read_json(\"/personalproject1/yelp_academic_dataset_review.json\", lines=True, nrows=num_lines_to_read)\n",
    "\n",
    "amazon_df = pd.read_json(\"/personalproject1/Cell_Phones_and_Accessories_5.json\", lines=True, nrows = num_lines_to_read)\n",
    "\n",
    "\n",
    "yelp_reviews.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>08 4, 2014</td>\n",
       "      <td>A24E3SXTC62LJI</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>{'Color:': ' Bling'}</td>\n",
       "      <td>Claudia Valdivia</td>\n",
       "      <td>Looks even better in person. Be careful to not...</td>\n",
       "      <td>Can't stop won't stop looking at it</td>\n",
       "      <td>1407110400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>02 12, 2014</td>\n",
       "      <td>A269FLZCB4GIPV</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sarah ponce</td>\n",
       "      <td>When you don't want to spend a whole lot of ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>1392163200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>02 8, 2014</td>\n",
       "      <td>AB6CHQWHZW4TV</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kai</td>\n",
       "      <td>so the case came on time, i love the design. I...</td>\n",
       "      <td>Its okay</td>\n",
       "      <td>1391817600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>02 4, 2014</td>\n",
       "      <td>A1M117A53LEI8</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sharon Williams</td>\n",
       "      <td>DON'T CARE FOR IT.  GAVE IT AS A GIFT AND THEY...</td>\n",
       "      <td>CASE</td>\n",
       "      <td>1391472000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>02 3, 2014</td>\n",
       "      <td>A272DUT8M88ZS8</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bella Rodriguez</td>\n",
       "      <td>I liked it because it was cute, but the studs ...</td>\n",
       "      <td>Cute!</td>\n",
       "      <td>1391385600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>01 27, 2014</td>\n",
       "      <td>A1DW2L6XCC5TJS</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>The product looked exactly like the picture an...</td>\n",
       "      <td>Not so happy</td>\n",
       "      <td>1390780800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>01 23, 2014</td>\n",
       "      <td>AQC61R4UST7UH</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DaMara Estep</td>\n",
       "      <td>I FINALLY got my case today. It took forever t...</td>\n",
       "      <td>It's cute!</td>\n",
       "      <td>1390435200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>01 17, 2014</td>\n",
       "      <td>A31OVFL91BCKXG</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ashley Nicole Miller</td>\n",
       "      <td>It is a very cute case. None of the jewels hav...</td>\n",
       "      <td>Cute case</td>\n",
       "      <td>1389916800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12 27, 2013</td>\n",
       "      <td>A1K0VLK6O5Z22M</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BeeLove21</td>\n",
       "      <td>DO NOT BUY! this item is seriously cheap as he...</td>\n",
       "      <td>WORST ITEM!</td>\n",
       "      <td>1388102400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>12 16, 2013</td>\n",
       "      <td>A1K3BWU73YB44P</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mrs. Ochoa</td>\n",
       "      <td>I really love this case... you have to keep yo...</td>\n",
       "      <td>Pretty Cute!</td>\n",
       "      <td>1387152000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0        5      True   08 4, 2014  A24E3SXTC62LJI  7508492919   \n",
       "1        5      True  02 12, 2014  A269FLZCB4GIPV  7508492919   \n",
       "2        3      True   02 8, 2014   AB6CHQWHZW4TV  7508492919   \n",
       "3        2      True   02 4, 2014   A1M117A53LEI8  7508492919   \n",
       "4        4      True   02 3, 2014  A272DUT8M88ZS8  7508492919   \n",
       "5        2      True  01 27, 2014  A1DW2L6XCC5TJS  7508492919   \n",
       "6        3      True  01 23, 2014   AQC61R4UST7UH  7508492919   \n",
       "7        5      True  01 17, 2014  A31OVFL91BCKXG  7508492919   \n",
       "8        1      True  12 27, 2013  A1K0VLK6O5Z22M  7508492919   \n",
       "9        4      True  12 16, 2013  A1K3BWU73YB44P  7508492919   \n",
       "\n",
       "                  style          reviewerName  \\\n",
       "0  {'Color:': ' Bling'}      Claudia Valdivia   \n",
       "1                   NaN           sarah ponce   \n",
       "2                   NaN                   Kai   \n",
       "3                   NaN       Sharon Williams   \n",
       "4                   NaN       Bella Rodriguez   \n",
       "5                   NaN       Amazon Customer   \n",
       "6                   NaN          DaMara Estep   \n",
       "7                   NaN  Ashley Nicole Miller   \n",
       "8                   NaN             BeeLove21   \n",
       "9                   NaN            Mrs. Ochoa   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  Looks even better in person. Be careful to not...   \n",
       "1  When you don't want to spend a whole lot of ca...   \n",
       "2  so the case came on time, i love the design. I...   \n",
       "3  DON'T CARE FOR IT.  GAVE IT AS A GIFT AND THEY...   \n",
       "4  I liked it because it was cute, but the studs ...   \n",
       "5  The product looked exactly like the picture an...   \n",
       "6  I FINALLY got my case today. It took forever t...   \n",
       "7  It is a very cute case. None of the jewels hav...   \n",
       "8  DO NOT BUY! this item is seriously cheap as he...   \n",
       "9  I really love this case... you have to keep yo...   \n",
       "\n",
       "                               summary  unixReviewTime vote image  \n",
       "0  Can't stop won't stop looking at it      1407110400  NaN   NaN  \n",
       "1                                    1      1392163200  NaN   NaN  \n",
       "2                             Its okay      1391817600  NaN   NaN  \n",
       "3                                 CASE      1391472000  NaN   NaN  \n",
       "4                                Cute!      1391385600  NaN   NaN  \n",
       "5                         Not so happy      1390780800  NaN   NaN  \n",
       "6                           It's cute!      1390435200  NaN   NaN  \n",
       "7                            Cute case      1389916800  NaN   NaN  \n",
       "8                          WORST ITEM!      1388102400  NaN   NaN  \n",
       "9                         Pretty Cute!      1387152000  NaN   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270385\n",
      "29615\n"
     ]
    }
   ],
   "source": [
    "verified_df = amazon_df[amazon_df['verified'] == True]\n",
    "unverified_df = amazon_df[amazon_df['verified'] == False]\n",
    "\n",
    "print(len(verified_df))\n",
    "print(len(unverified_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTextCleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Looks even better in person. Be careful to not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>When you don't want to spend a whole lot of ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>so the case came on time, i love the design. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>DON'T CARE FOR IT.  GAVE IT AS A GIFT AND THEY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I liked it because it was cute, but the studs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>The product looked exactly like the picture an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>I FINALLY got my case today. It took forever t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>It is a very cute case. None of the jewels hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>DO NOT BUY! this item is seriously cheap as he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>I really love this case... you have to keep yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall                                  reviewTextCleaned\n",
       "0        5  Looks even better in person. Be careful to not...\n",
       "1        5  When you don't want to spend a whole lot of ca...\n",
       "2        3  so the case came on time, i love the design. I...\n",
       "3        2  DON'T CARE FOR IT.  GAVE IT AS A GIFT AND THEY...\n",
       "4        4  I liked it because it was cute, but the studs ...\n",
       "5        2  The product looked exactly like the picture an...\n",
       "6        3  I FINALLY got my case today. It took forever t...\n",
       "7        5  It is a very cute case. None of the jewels hav...\n",
       "8        1  DO NOT BUY! this item is seriously cheap as he...\n",
       "9        4  I really love this case... you have to keep yo..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def review_to_string(content):\n",
    "    return str(content)\n",
    "\n",
    "amazon_reviews_cleaned = amazon_df[['overall', 'reviewText']]\n",
    "amazon_reviews_final = amazon_reviews_cleaned.copy(deep = True)\n",
    "amazon_reviews_final['reviewTextCleaned'] = amazon_reviews_final['reviewText'].apply(lambda x: review_to_string(x))\n",
    "amazon_reviews_final = amazon_reviews_final[['overall', 'reviewTextCleaned']]\n",
    "\n",
    "amazon_reviews_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall\n",
      "5    178043\n",
      "4     53212\n",
      "3     29807\n",
      "1     22546\n",
      "2     16392\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts = amazon_reviews_final['overall'].value_counts()\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall\n",
      "3    100000\n",
      "5     77079\n",
      "1     58155\n",
      "2     41845\n",
      "4     22921\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "high_class = amazon_reviews_final[amazon_reviews_final['overall'].isin([4,5])]\n",
    "neutral_class = amazon_reviews_final[amazon_reviews_final['overall'] == 3]\n",
    "low_class = amazon_reviews_final[amazon_reviews_final['overall'].isin([1,2])]\n",
    "\n",
    "undersampled_high = high_class.sample(n=100000, random_state = 42)\n",
    "oversampled_low = low_class.sample(n=100000, replace = True, random_state = 42)\n",
    "oversampled_neutral = neutral_class.sample(n=100000, replace = True, random_state = 42)\n",
    "\n",
    "amazon_reviews_final = pd.concat([undersampled_high, oversampled_low, oversampled_neutral], axis=0)\n",
    "\n",
    "value_counts = amazon_reviews_final['overall'].value_counts()\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stars\n",
      "5    133282\n",
      "4     75164\n",
      "3     33989\n",
      "1     33403\n",
      "2     24162\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "yelp_reviews_cleaned = yelp_reviews[['stars', 'text']]\n",
    "yelp_reviews_final = yelp_reviews_cleaned.copy(deep = True)\n",
    "yelp_reviews_final['reviewTextCleaned'] = yelp_reviews_final['text'].apply(lambda x: review_to_string(x))\n",
    "yelp_reviews_final = yelp_reviews_final[['stars', 'reviewTextCleaned']]\n",
    "\n",
    "yelp_reviews_final.head(10)\n",
    "\n",
    "value_counts = yelp_reviews_final['stars'].value_counts()\n",
    "\n",
    "print(value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stars\n",
      "3    100000\n",
      "5     63777\n",
      "1     57852\n",
      "2     42148\n",
      "4     36223\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "high_class = yelp_reviews_final[yelp_reviews_final['stars'].isin([4,5])]\n",
    "neutral_class = yelp_reviews_final[yelp_reviews_final['stars'] == 3]\n",
    "low_class = yelp_reviews_final[yelp_reviews_final['stars'].isin([1,2])]\n",
    "\n",
    "undersampled_high = high_class.sample(n=100000, random_state = 42)\n",
    "oversampled_low = low_class.sample(n=100000, replace = True, random_state = 42)\n",
    "oversampled_neutral = neutral_class.sample(n=100000, replace = True, random_state = 42)\n",
    "\n",
    "yelp_reviews_final = pd.concat([undersampled_high, oversampled_low, oversampled_neutral], axis=0)\n",
    "\n",
    "value_counts = yelp_reviews_final['stars'].value_counts()\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTextCleaned</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141321</th>\n",
       "      <td>5</td>\n",
       "      <td>Good for the price</td>\n",
       "      <td>[good, price]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59316</th>\n",
       "      <td>4</td>\n",
       "      <td>It works for its purpose in holding the cards ...</td>\n",
       "      <td>[works, purpose, holding, cards, beware, drop,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158003</th>\n",
       "      <td>4</td>\n",
       "      <td>Hello dear,\\nI received my order, it is very g...</td>\n",
       "      <td>[hello, dear, received, order, good, like, wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56282</th>\n",
       "      <td>5</td>\n",
       "      <td>Exactly as advertised. Got 2 screen savers, ea...</td>\n",
       "      <td>[exactly, advertised, got, screen, savers, eas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133591</th>\n",
       "      <td>5</td>\n",
       "      <td>great projuct fits perfectly and works well</td>\n",
       "      <td>[great, projuct, fits, perfectly, works, well]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95297</th>\n",
       "      <td>5</td>\n",
       "      <td>This case material is the very best. Just wish...</td>\n",
       "      <td>[case, material, best, wish, would, make, cred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118974</th>\n",
       "      <td>5</td>\n",
       "      <td>Picked this up for my sister.  The case fits h...</td>\n",
       "      <td>[picked, sister, case, fits, phone, perfectly,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7123</th>\n",
       "      <td>5</td>\n",
       "      <td>Pretty simple case and that was all I wanted. ...</td>\n",
       "      <td>[pretty, simple, case, wanted, magnet, type, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87133</th>\n",
       "      <td>5</td>\n",
       "      <td>With this charger and my backup battery I'm ne...</td>\n",
       "      <td>[charger, backup, battery, never, without, pow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194191</th>\n",
       "      <td>5</td>\n",
       "      <td>i loved it just once again didn't protect the ...</td>\n",
       "      <td>[loved, protect, front, phone, well, fit, phon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall                                  reviewTextCleaned  \\\n",
       "141321        5                                 Good for the price   \n",
       "59316         4  It works for its purpose in holding the cards ...   \n",
       "158003        4  Hello dear,\\nI received my order, it is very g...   \n",
       "56282         5  Exactly as advertised. Got 2 screen savers, ea...   \n",
       "133591        5        great projuct fits perfectly and works well   \n",
       "95297         5  This case material is the very best. Just wish...   \n",
       "118974        5  Picked this up for my sister.  The case fits h...   \n",
       "7123          5  Pretty simple case and that was all I wanted. ...   \n",
       "87133         5  With this charger and my backup battery I'm ne...   \n",
       "194191        5  i loved it just once again didn't protect the ...   \n",
       "\n",
       "                                                tokenized  \n",
       "141321                                      [good, price]  \n",
       "59316   [works, purpose, holding, cards, beware, drop,...  \n",
       "158003  [hello, dear, received, order, good, like, wan...  \n",
       "56282   [exactly, advertised, got, screen, savers, eas...  \n",
       "133591     [great, projuct, fits, perfectly, works, well]  \n",
       "95297   [case, material, best, wish, would, make, cred...  \n",
       "118974  [picked, sister, case, fits, phone, perfectly,...  \n",
       "7123    [pretty, simple, case, wanted, magnet, type, s...  \n",
       "87133   [charger, backup, battery, never, without, pow...  \n",
       "194191  [loved, protect, front, phone, well, fit, phon...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_content(content):\n",
    "  tokenized_text = nltk.word_tokenize(content)\n",
    "  words=[word.lower() for word in tokenized_text if word.isalpha()]\n",
    "  words = [word for word in words if word not in stopwords]\n",
    "  return words\n",
    "\n",
    "\n",
    "amazon_reviews_tokenized = amazon_reviews_final.copy(deep=True)\n",
    "amazon_reviews_tokenized['tokenized'] = amazon_reviews_tokenized['reviewTextCleaned'].apply(lambda x: tokenize_content(x))\n",
    "amazon_reviews_tokenized.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>reviewTextCleaned</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218044</th>\n",
       "      <td>5</td>\n",
       "      <td>Fixed a belt no charge,  Fixed 2 pairs of shoe...</td>\n",
       "      <td>[fixed, belt, charge, fixed, pairs, shoes, cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196648</th>\n",
       "      <td>5</td>\n",
       "      <td>We went here for dinner on a quiet night (Sund...</td>\n",
       "      <td>[went, dinner, quiet, night, sunday, service, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282669</th>\n",
       "      <td>4</td>\n",
       "      <td>Mmmmm so delicious!!  We love this place!  All...</td>\n",
       "      <td>[mmmmm, delicious, love, place, flavors, delic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58499</th>\n",
       "      <td>4</td>\n",
       "      <td>Lovely dining experience with delicious buffet...</td>\n",
       "      <td>[lovely, dining, experience, delicious, buffet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278453</th>\n",
       "      <td>5</td>\n",
       "      <td>I really like Rubyz! I've only gone twice, and...</td>\n",
       "      <td>[really, like, rubyz, gone, twice, times, posi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180995</th>\n",
       "      <td>5</td>\n",
       "      <td>The quintessential St. Louis experience.  \\nDo...</td>\n",
       "      <td>[quintessential, louis, experience, afraid, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229038</th>\n",
       "      <td>5</td>\n",
       "      <td>I'm not a tea guy or big into pastries. But I ...</td>\n",
       "      <td>[tea, guy, big, pastries, admit, fell, love, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90536</th>\n",
       "      <td>4</td>\n",
       "      <td>Had the tabasco honey fried chicken with beans...</td>\n",
       "      <td>[tabasco, honey, fried, chicken, beans, rice, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169227</th>\n",
       "      <td>5</td>\n",
       "      <td>The food was awesome and the service was great...</td>\n",
       "      <td>[food, awesome, service, great, best, italian,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118951</th>\n",
       "      <td>5</td>\n",
       "      <td>Good selection of beer on tap! Good prime rib ...</td>\n",
       "      <td>[good, selection, beer, tap, good, prime, rib,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        stars                                  reviewTextCleaned  \\\n",
       "218044      5  Fixed a belt no charge,  Fixed 2 pairs of shoe...   \n",
       "196648      5  We went here for dinner on a quiet night (Sund...   \n",
       "282669      4  Mmmmm so delicious!!  We love this place!  All...   \n",
       "58499       4  Lovely dining experience with delicious buffet...   \n",
       "278453      5  I really like Rubyz! I've only gone twice, and...   \n",
       "180995      5  The quintessential St. Louis experience.  \\nDo...   \n",
       "229038      5  I'm not a tea guy or big into pastries. But I ...   \n",
       "90536       4  Had the tabasco honey fried chicken with beans...   \n",
       "169227      5  The food was awesome and the service was great...   \n",
       "118951      5  Good selection of beer on tap! Good prime rib ...   \n",
       "\n",
       "                                                tokenized  \n",
       "218044  [fixed, belt, charge, fixed, pairs, shoes, cou...  \n",
       "196648  [went, dinner, quiet, night, sunday, service, ...  \n",
       "282669  [mmmmm, delicious, love, place, flavors, delic...  \n",
       "58499   [lovely, dining, experience, delicious, buffet...  \n",
       "278453  [really, like, rubyz, gone, twice, times, posi...  \n",
       "180995  [quintessential, louis, experience, afraid, li...  \n",
       "229038  [tea, guy, big, pastries, admit, fell, love, s...  \n",
       "90536   [tabasco, honey, fried, chicken, beans, rice, ...  \n",
       "169227  [food, awesome, service, great, best, italian,...  \n",
       "118951  [good, selection, beer, tap, good, prime, rib,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews_tokenized = yelp_reviews_final.copy(deep=True)\n",
    "yelp_reviews_tokenized['tokenized'] = yelp_reviews_tokenized['reviewTextCleaned'].apply(lambda x: tokenize_content(x))\n",
    "yelp_reviews_tokenized.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_sentiment(content):\n",
    "  return sia.polarity_scores(content)['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTextCleaned</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188430</th>\n",
       "      <td>5</td>\n",
       "      <td>UPDATE: Last week, T-Mobile sent a patch to An...</td>\n",
       "      <td>[update, last, week, sent, patch, android, jel...</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297400</th>\n",
       "      <td>5</td>\n",
       "      <td>I own the LG G2 and it is a replacement for my...</td>\n",
       "      <td>[lg, replacement, nearly, year, old, verizon, ...</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90019</th>\n",
       "      <td>5</td>\n",
       "      <td>I recently began working for AT&amp;T, so let me g...</td>\n",
       "      <td>[recently, began, working, let, get, right, aw...</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172930</th>\n",
       "      <td>5</td>\n",
       "      <td>_________________________________________\\n\\nA...</td>\n",
       "      <td>[review, first, lumia, iphone, master, maps, m...</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124551</th>\n",
       "      <td>5</td>\n",
       "      <td>I'd been stuck with a Droid X on another big c...</td>\n",
       "      <td>[stuck, droid, x, another, big, carrier, nearl...</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117725</th>\n",
       "      <td>4</td>\n",
       "      <td>First off, let me come clean, I currently work...</td>\n",
       "      <td>[first, let, come, clean, currently, work, aut...</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107192</th>\n",
       "      <td>3</td>\n",
       "      <td>For years I've heard how great the iPhone is a...</td>\n",
       "      <td>[years, heard, great, iphone, every, iteration...</td>\n",
       "      <td>0.9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192513</th>\n",
       "      <td>4</td>\n",
       "      <td>---Intro---\\n\\nThe worst thing about getting t...</td>\n",
       "      <td>[worst, thing, getting, amazing, phone, lack, ...</td>\n",
       "      <td>0.9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107192</th>\n",
       "      <td>3</td>\n",
       "      <td>For years I've heard how great the iPhone is a...</td>\n",
       "      <td>[years, heard, great, iphone, every, iteration...</td>\n",
       "      <td>0.9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171787</th>\n",
       "      <td>4</td>\n",
       "      <td>---Intro---\\n\\nThe worst thing about getting t...</td>\n",
       "      <td>[worst, thing, getting, amazing, phone, lack, ...</td>\n",
       "      <td>0.9998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall                                  reviewTextCleaned  \\\n",
       "188430        5  UPDATE: Last week, T-Mobile sent a patch to An...   \n",
       "297400        5  I own the LG G2 and it is a replacement for my...   \n",
       "90019         5  I recently began working for AT&T, so let me g...   \n",
       "172930        5  _________________________________________\\n\\nA...   \n",
       "124551        5  I'd been stuck with a Droid X on another big c...   \n",
       "117725        4  First off, let me come clean, I currently work...   \n",
       "107192        3  For years I've heard how great the iPhone is a...   \n",
       "192513        4  ---Intro---\\n\\nThe worst thing about getting t...   \n",
       "107192        3  For years I've heard how great the iPhone is a...   \n",
       "171787        4  ---Intro---\\n\\nThe worst thing about getting t...   \n",
       "\n",
       "                                                tokenized  sentiment  \n",
       "188430  [update, last, week, sent, patch, android, jel...     0.9999  \n",
       "297400  [lg, replacement, nearly, year, old, verizon, ...     0.9999  \n",
       "90019   [recently, began, working, let, get, right, aw...     0.9999  \n",
       "172930  [review, first, lumia, iphone, master, maps, m...     0.9999  \n",
       "124551  [stuck, droid, x, another, big, carrier, nearl...     0.9999  \n",
       "117725  [first, let, come, clean, currently, work, aut...     0.9999  \n",
       "107192  [years, heard, great, iphone, every, iteration...     0.9998  \n",
       "192513  [worst, thing, getting, amazing, phone, lack, ...     0.9998  \n",
       "107192  [years, heard, great, iphone, every, iteration...     0.9998  \n",
       "171787  [worst, thing, getting, amazing, phone, lack, ...     0.9998  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_reviews_tokenized['sentiment'] = amazon_reviews_tokenized['reviewTextCleaned'].apply(lambda x: retrieve_sentiment(x))\n",
    "amazon_reviews_tokenized = amazon_reviews_tokenized.sort_values(by=['sentiment'], ascending=False)\n",
    "amazon_reviews_tokenized.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>reviewTextCleaned</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126641</th>\n",
       "      <td>5</td>\n",
       "      <td>First thing first is you are entering paradise...</td>\n",
       "      <td>[first, thing, first, entering, paradise, plac...</td>\n",
       "      <td>0.9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150202</th>\n",
       "      <td>5</td>\n",
       "      <td>It's been a while since I dined at Chef Yoshi ...</td>\n",
       "      <td>[since, dined, chef, yoshi, chubachi, wildflow...</td>\n",
       "      <td>0.9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114162</th>\n",
       "      <td>3</td>\n",
       "      <td>Headline: GOOD, NOT GREAT - DECENT VALUE\\n\\nOV...</td>\n",
       "      <td>[headline, good, great, decent, value, overall...</td>\n",
       "      <td>0.9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114162</th>\n",
       "      <td>3</td>\n",
       "      <td>Headline: GOOD, NOT GREAT - DECENT VALUE\\n\\nOV...</td>\n",
       "      <td>[headline, good, great, decent, value, overall...</td>\n",
       "      <td>0.9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114162</th>\n",
       "      <td>3</td>\n",
       "      <td>Headline: GOOD, NOT GREAT - DECENT VALUE\\n\\nOV...</td>\n",
       "      <td>[headline, good, great, decent, value, overall...</td>\n",
       "      <td>0.9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114162</th>\n",
       "      <td>3</td>\n",
       "      <td>Headline: GOOD, NOT GREAT - DECENT VALUE\\n\\nOV...</td>\n",
       "      <td>[headline, good, great, decent, value, overall...</td>\n",
       "      <td>0.9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114162</th>\n",
       "      <td>3</td>\n",
       "      <td>Headline: GOOD, NOT GREAT - DECENT VALUE\\n\\nOV...</td>\n",
       "      <td>[headline, good, great, decent, value, overall...</td>\n",
       "      <td>0.9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114162</th>\n",
       "      <td>3</td>\n",
       "      <td>Headline: GOOD, NOT GREAT - DECENT VALUE\\n\\nOV...</td>\n",
       "      <td>[headline, good, great, decent, value, overall...</td>\n",
       "      <td>0.9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61518</th>\n",
       "      <td>5</td>\n",
       "      <td>This is my love letter to Stacey.\\n\\n\\nI've be...</td>\n",
       "      <td>[love, letter, stacey, famous, tattoo, parlors...</td>\n",
       "      <td>0.9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63521</th>\n",
       "      <td>5</td>\n",
       "      <td>Yes, yes and another hell yes! I love this pla...</td>\n",
       "      <td>[yes, yes, another, hell, yes, love, place, se...</td>\n",
       "      <td>0.9996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        stars                                  reviewTextCleaned  \\\n",
       "126641      5  First thing first is you are entering paradise...   \n",
       "150202      5  It's been a while since I dined at Chef Yoshi ...   \n",
       "114162      3  Headline: GOOD, NOT GREAT - DECENT VALUE\\n\\nOV...   \n",
       "114162      3  Headline: GOOD, NOT GREAT - DECENT VALUE\\n\\nOV...   \n",
       "114162      3  Headline: GOOD, NOT GREAT - DECENT VALUE\\n\\nOV...   \n",
       "114162      3  Headline: GOOD, NOT GREAT - DECENT VALUE\\n\\nOV...   \n",
       "114162      3  Headline: GOOD, NOT GREAT - DECENT VALUE\\n\\nOV...   \n",
       "114162      3  Headline: GOOD, NOT GREAT - DECENT VALUE\\n\\nOV...   \n",
       "61518       5  This is my love letter to Stacey.\\n\\n\\nI've be...   \n",
       "63521       5  Yes, yes and another hell yes! I love this pla...   \n",
       "\n",
       "                                                tokenized  sentiment  \n",
       "126641  [first, thing, first, entering, paradise, plac...     0.9998  \n",
       "150202  [since, dined, chef, yoshi, chubachi, wildflow...     0.9997  \n",
       "114162  [headline, good, great, decent, value, overall...     0.9997  \n",
       "114162  [headline, good, great, decent, value, overall...     0.9997  \n",
       "114162  [headline, good, great, decent, value, overall...     0.9997  \n",
       "114162  [headline, good, great, decent, value, overall...     0.9997  \n",
       "114162  [headline, good, great, decent, value, overall...     0.9997  \n",
       "114162  [headline, good, great, decent, value, overall...     0.9997  \n",
       "61518   [love, letter, stacey, famous, tattoo, parlors...     0.9997  \n",
       "63521   [yes, yes, another, hell, yes, love, place, se...     0.9996  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews_tokenized['sentiment'] = yelp_reviews_tokenized['reviewTextCleaned'].apply(lambda x: retrieve_sentiment(x))\n",
    "yelp_reviews_tokenized = yelp_reviews_tokenized.sort_values(by=['sentiment'], ascending=False)\n",
    "yelp_reviews_tokenized.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>reviewTextCleaned</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115777</th>\n",
       "      <td>1</td>\n",
       "      <td>I've been to the C &amp; B in Charleston, but last...</td>\n",
       "      <td>[c, b, charleston, last, night, first, time, n...</td>\n",
       "      <td>-0.9989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115777</th>\n",
       "      <td>1</td>\n",
       "      <td>I've been to the C &amp; B in Charleston, but last...</td>\n",
       "      <td>[c, b, charleston, last, night, first, time, n...</td>\n",
       "      <td>-0.9989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89360</th>\n",
       "      <td>1</td>\n",
       "      <td>WATCH YOUR BILL!! The laminated menus have pri...</td>\n",
       "      <td>[watch, bill, laminated, menus, prices, match,...</td>\n",
       "      <td>-0.9988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135791</th>\n",
       "      <td>1</td>\n",
       "      <td>Me thinks NOT/NEVER AGAIN is the perfect way t...</td>\n",
       "      <td>[thinks, perfect, way, describe, experience, l...</td>\n",
       "      <td>-0.9988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237418</th>\n",
       "      <td>1</td>\n",
       "      <td>SHARING MY STORY ABOUT THE UNIT HUM BY VERIZON...</td>\n",
       "      <td>[sharing, story, unit, hum, verizon, ripped, c...</td>\n",
       "      <td>-0.9987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237418</th>\n",
       "      <td>1</td>\n",
       "      <td>SHARING MY STORY ABOUT THE UNIT HUM BY VERIZON...</td>\n",
       "      <td>[sharing, story, unit, hum, verizon, ripped, c...</td>\n",
       "      <td>-0.9987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237418</th>\n",
       "      <td>1</td>\n",
       "      <td>SHARING MY STORY ABOUT THE UNIT HUM BY VERIZON...</td>\n",
       "      <td>[sharing, story, unit, hum, verizon, ripped, c...</td>\n",
       "      <td>-0.9987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113244</th>\n",
       "      <td>2</td>\n",
       "      <td>I'll preface this review by saying that I've h...</td>\n",
       "      <td>[preface, review, saying, great, experiences, ...</td>\n",
       "      <td>-0.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113244</th>\n",
       "      <td>2</td>\n",
       "      <td>I'll preface this review by saying that I've h...</td>\n",
       "      <td>[preface, review, saying, great, experiences, ...</td>\n",
       "      <td>-0.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31932</th>\n",
       "      <td>1</td>\n",
       "      <td>DO NOT USE EMPIRE TODAY for your carpets/floor...</td>\n",
       "      <td>[use, empire, today, asked, daughter, write, p...</td>\n",
       "      <td>-0.9979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        stars                                  reviewTextCleaned  \\\n",
       "115777      1  I've been to the C & B in Charleston, but last...   \n",
       "115777      1  I've been to the C & B in Charleston, but last...   \n",
       "89360       1  WATCH YOUR BILL!! The laminated menus have pri...   \n",
       "135791      1  Me thinks NOT/NEVER AGAIN is the perfect way t...   \n",
       "237418      1  SHARING MY STORY ABOUT THE UNIT HUM BY VERIZON...   \n",
       "237418      1  SHARING MY STORY ABOUT THE UNIT HUM BY VERIZON...   \n",
       "237418      1  SHARING MY STORY ABOUT THE UNIT HUM BY VERIZON...   \n",
       "113244      2  I'll preface this review by saying that I've h...   \n",
       "113244      2  I'll preface this review by saying that I've h...   \n",
       "31932       1  DO NOT USE EMPIRE TODAY for your carpets/floor...   \n",
       "\n",
       "                                                tokenized  sentiment  \n",
       "115777  [c, b, charleston, last, night, first, time, n...    -0.9989  \n",
       "115777  [c, b, charleston, last, night, first, time, n...    -0.9989  \n",
       "89360   [watch, bill, laminated, menus, prices, match,...    -0.9988  \n",
       "135791  [thinks, perfect, way, describe, experience, l...    -0.9988  \n",
       "237418  [sharing, story, unit, hum, verizon, ripped, c...    -0.9987  \n",
       "237418  [sharing, story, unit, hum, verizon, ripped, c...    -0.9987  \n",
       "237418  [sharing, story, unit, hum, verizon, ripped, c...    -0.9987  \n",
       "113244  [preface, review, saying, great, experiences, ...    -0.9981  \n",
       "113244  [preface, review, saying, great, experiences, ...    -0.9981  \n",
       "31932   [use, empire, today, asked, daughter, write, p...    -0.9979  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews_tokenized = yelp_reviews_tokenized.sort_values(by=['sentiment'], ascending=True)\n",
    "\n",
    "yelp_reviews_tokenized.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>reviewTextCleaned</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115777</th>\n",
       "      <td>1</td>\n",
       "      <td>I've been to the C &amp; B in Charleston, but last...</td>\n",
       "      <td>[c, b, charleston, last, night, first, time, n...</td>\n",
       "      <td>-0.9989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80065</th>\n",
       "      <td>1</td>\n",
       "      <td>High prices, slow service, &amp; wrong orders.\\nNe...</td>\n",
       "      <td>[high, prices, slow, service, wrong, orders, n...</td>\n",
       "      <td>-0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42828</th>\n",
       "      <td>1</td>\n",
       "      <td>Awful. My advice is do not order from here. As...</td>\n",
       "      <td>[awful, advice, order, asked, well, done, pizz...</td>\n",
       "      <td>-0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257662</th>\n",
       "      <td>1</td>\n",
       "      <td>Stay away from Erin, I had a terrible experien...</td>\n",
       "      <td>[stay, away, erin, terrible, experience, know,...</td>\n",
       "      <td>-0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60585</th>\n",
       "      <td>1</td>\n",
       "      <td>Previous reviewer's description as a redneck j...</td>\n",
       "      <td>[previous, reviewer, description, redneck, joi...</td>\n",
       "      <td>-0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279146</th>\n",
       "      <td>1</td>\n",
       "      <td>Absolutely awful customer service. Had a 2:30 ...</td>\n",
       "      <td>[absolutely, awful, customer, service, reserva...</td>\n",
       "      <td>0.1874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279146</th>\n",
       "      <td>1</td>\n",
       "      <td>Absolutely awful customer service. Had a 2:30 ...</td>\n",
       "      <td>[absolutely, awful, customer, service, reserva...</td>\n",
       "      <td>0.1874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131505</th>\n",
       "      <td>1</td>\n",
       "      <td>The manager is very manipulative, We went to a...</td>\n",
       "      <td>[manager, manipulative, went, event, spoke, ba...</td>\n",
       "      <td>-0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52918</th>\n",
       "      <td>1</td>\n",
       "      <td>This store should be called knitter's nightmar...</td>\n",
       "      <td>[store, called, knitter, nightmare, went, purc...</td>\n",
       "      <td>0.5735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232550</th>\n",
       "      <td>1</td>\n",
       "      <td>Overpriced Sysco food is about the only way to...</td>\n",
       "      <td>[overpriced, sysco, food, way, describe, serve...</td>\n",
       "      <td>-0.4767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        stars                                  reviewTextCleaned  \\\n",
       "115777      1  I've been to the C & B in Charleston, but last...   \n",
       "80065       1  High prices, slow service, & wrong orders.\\nNe...   \n",
       "42828       1  Awful. My advice is do not order from here. As...   \n",
       "257662      1  Stay away from Erin, I had a terrible experien...   \n",
       "60585       1  Previous reviewer's description as a redneck j...   \n",
       "279146      1  Absolutely awful customer service. Had a 2:30 ...   \n",
       "279146      1  Absolutely awful customer service. Had a 2:30 ...   \n",
       "131505      1  The manager is very manipulative, We went to a...   \n",
       "52918       1  This store should be called knitter's nightmar...   \n",
       "232550      1  Overpriced Sysco food is about the only way to...   \n",
       "\n",
       "                                                tokenized  sentiment  \n",
       "115777  [c, b, charleston, last, night, first, time, n...    -0.9989  \n",
       "80065   [high, prices, slow, service, wrong, orders, n...    -0.4767  \n",
       "42828   [awful, advice, order, asked, well, done, pizz...    -0.4767  \n",
       "257662  [stay, away, erin, terrible, experience, know,...    -0.4767  \n",
       "60585   [previous, reviewer, description, redneck, joi...    -0.4767  \n",
       "279146  [absolutely, awful, customer, service, reserva...     0.1874  \n",
       "279146  [absolutely, awful, customer, service, reserva...     0.1874  \n",
       "131505  [manager, manipulative, went, event, spoke, ba...    -0.4767  \n",
       "52918   [store, called, knitter, nightmare, went, purc...     0.5735  \n",
       "232550  [overpriced, sysco, food, way, describe, serve...    -0.4767  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews_tokenized = yelp_reviews_tokenized.sort_values(by=['stars'], ascending=True)\n",
    "\n",
    "yelp_reviews_tokenized.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get high and low for sentiment\n",
    "#create column for high/neutral/low ratings based on overall/stars\n",
    "#create column for high/neutral/low sentiment\n",
    "#create column for == ^^\n",
    "#num == / num != + num == is accuracy\n",
    "def high_or_low_stars(stars):\n",
    "    if stars > 3:\n",
    "        return \"High\"\n",
    "    elif stars > 2:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "def high_or_low_sentiment(sentiment):\n",
    "    if sentiment > .2:\n",
    "        return \"High\"\n",
    "    elif sentiment > -.2:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>reviewTextCleaned</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>high_low_sentiment</th>\n",
       "      <th>high_low_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115777</th>\n",
       "      <td>1</td>\n",
       "      <td>I've been to the C &amp; B in Charleston, but last...</td>\n",
       "      <td>[c, b, charleston, last, night, first, time, n...</td>\n",
       "      <td>-0.9989</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80065</th>\n",
       "      <td>1</td>\n",
       "      <td>High prices, slow service, &amp; wrong orders.\\nNe...</td>\n",
       "      <td>[high, prices, slow, service, wrong, orders, n...</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42828</th>\n",
       "      <td>1</td>\n",
       "      <td>Awful. My advice is do not order from here. As...</td>\n",
       "      <td>[awful, advice, order, asked, well, done, pizz...</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257662</th>\n",
       "      <td>1</td>\n",
       "      <td>Stay away from Erin, I had a terrible experien...</td>\n",
       "      <td>[stay, away, erin, terrible, experience, know,...</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60585</th>\n",
       "      <td>1</td>\n",
       "      <td>Previous reviewer's description as a redneck j...</td>\n",
       "      <td>[previous, reviewer, description, redneck, joi...</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279146</th>\n",
       "      <td>1</td>\n",
       "      <td>Absolutely awful customer service. Had a 2:30 ...</td>\n",
       "      <td>[absolutely, awful, customer, service, reserva...</td>\n",
       "      <td>0.1874</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279146</th>\n",
       "      <td>1</td>\n",
       "      <td>Absolutely awful customer service. Had a 2:30 ...</td>\n",
       "      <td>[absolutely, awful, customer, service, reserva...</td>\n",
       "      <td>0.1874</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131505</th>\n",
       "      <td>1</td>\n",
       "      <td>The manager is very manipulative, We went to a...</td>\n",
       "      <td>[manager, manipulative, went, event, spoke, ba...</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52918</th>\n",
       "      <td>1</td>\n",
       "      <td>This store should be called knitter's nightmar...</td>\n",
       "      <td>[store, called, knitter, nightmare, went, purc...</td>\n",
       "      <td>0.5735</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232550</th>\n",
       "      <td>1</td>\n",
       "      <td>Overpriced Sysco food is about the only way to...</td>\n",
       "      <td>[overpriced, sysco, food, way, describe, serve...</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        stars                                  reviewTextCleaned  \\\n",
       "115777      1  I've been to the C & B in Charleston, but last...   \n",
       "80065       1  High prices, slow service, & wrong orders.\\nNe...   \n",
       "42828       1  Awful. My advice is do not order from here. As...   \n",
       "257662      1  Stay away from Erin, I had a terrible experien...   \n",
       "60585       1  Previous reviewer's description as a redneck j...   \n",
       "279146      1  Absolutely awful customer service. Had a 2:30 ...   \n",
       "279146      1  Absolutely awful customer service. Had a 2:30 ...   \n",
       "131505      1  The manager is very manipulative, We went to a...   \n",
       "52918       1  This store should be called knitter's nightmar...   \n",
       "232550      1  Overpriced Sysco food is about the only way to...   \n",
       "\n",
       "                                                tokenized  sentiment  \\\n",
       "115777  [c, b, charleston, last, night, first, time, n...    -0.9989   \n",
       "80065   [high, prices, slow, service, wrong, orders, n...    -0.4767   \n",
       "42828   [awful, advice, order, asked, well, done, pizz...    -0.4767   \n",
       "257662  [stay, away, erin, terrible, experience, know,...    -0.4767   \n",
       "60585   [previous, reviewer, description, redneck, joi...    -0.4767   \n",
       "279146  [absolutely, awful, customer, service, reserva...     0.1874   \n",
       "279146  [absolutely, awful, customer, service, reserva...     0.1874   \n",
       "131505  [manager, manipulative, went, event, spoke, ba...    -0.4767   \n",
       "52918   [store, called, knitter, nightmare, went, purc...     0.5735   \n",
       "232550  [overpriced, sysco, food, way, describe, serve...    -0.4767   \n",
       "\n",
       "       high_low_sentiment high_low_stars  \n",
       "115777                Low            Low  \n",
       "80065                 Low            Low  \n",
       "42828                 Low            Low  \n",
       "257662                Low            Low  \n",
       "60585                 Low            Low  \n",
       "279146            Neutral            Low  \n",
       "279146            Neutral            Low  \n",
       "131505                Low            Low  \n",
       "52918                High            Low  \n",
       "232550                Low            Low  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews_tokenized['high_low_sentiment'] = yelp_reviews_tokenized['sentiment'].apply(lambda x: high_or_low_sentiment(x))\n",
    "yelp_reviews_tokenized['high_low_stars'] = yelp_reviews_tokenized['stars'].apply(lambda x: high_or_low_stars(x))\n",
    "\n",
    "\n",
    "\n",
    "yelp_reviews_tokenized.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTextCleaned</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>high_low_sentiment</th>\n",
       "      <th>high_low_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188430</th>\n",
       "      <td>5</td>\n",
       "      <td>UPDATE: Last week, T-Mobile sent a patch to An...</td>\n",
       "      <td>[update, last, week, sent, patch, android, jel...</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297400</th>\n",
       "      <td>5</td>\n",
       "      <td>I own the LG G2 and it is a replacement for my...</td>\n",
       "      <td>[lg, replacement, nearly, year, old, verizon, ...</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90019</th>\n",
       "      <td>5</td>\n",
       "      <td>I recently began working for AT&amp;T, so let me g...</td>\n",
       "      <td>[recently, began, working, let, get, right, aw...</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172930</th>\n",
       "      <td>5</td>\n",
       "      <td>_________________________________________\\n\\nA...</td>\n",
       "      <td>[review, first, lumia, iphone, master, maps, m...</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124551</th>\n",
       "      <td>5</td>\n",
       "      <td>I'd been stuck with a Droid X on another big c...</td>\n",
       "      <td>[stuck, droid, x, another, big, carrier, nearl...</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117725</th>\n",
       "      <td>4</td>\n",
       "      <td>First off, let me come clean, I currently work...</td>\n",
       "      <td>[first, let, come, clean, currently, work, aut...</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107192</th>\n",
       "      <td>3</td>\n",
       "      <td>For years I've heard how great the iPhone is a...</td>\n",
       "      <td>[years, heard, great, iphone, every, iteration...</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>High</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192513</th>\n",
       "      <td>4</td>\n",
       "      <td>---Intro---\\n\\nThe worst thing about getting t...</td>\n",
       "      <td>[worst, thing, getting, amazing, phone, lack, ...</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107192</th>\n",
       "      <td>3</td>\n",
       "      <td>For years I've heard how great the iPhone is a...</td>\n",
       "      <td>[years, heard, great, iphone, every, iteration...</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>High</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171787</th>\n",
       "      <td>4</td>\n",
       "      <td>---Intro---\\n\\nThe worst thing about getting t...</td>\n",
       "      <td>[worst, thing, getting, amazing, phone, lack, ...</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall                                  reviewTextCleaned  \\\n",
       "188430        5  UPDATE: Last week, T-Mobile sent a patch to An...   \n",
       "297400        5  I own the LG G2 and it is a replacement for my...   \n",
       "90019         5  I recently began working for AT&T, so let me g...   \n",
       "172930        5  _________________________________________\\n\\nA...   \n",
       "124551        5  I'd been stuck with a Droid X on another big c...   \n",
       "117725        4  First off, let me come clean, I currently work...   \n",
       "107192        3  For years I've heard how great the iPhone is a...   \n",
       "192513        4  ---Intro---\\n\\nThe worst thing about getting t...   \n",
       "107192        3  For years I've heard how great the iPhone is a...   \n",
       "171787        4  ---Intro---\\n\\nThe worst thing about getting t...   \n",
       "\n",
       "                                                tokenized  sentiment  \\\n",
       "188430  [update, last, week, sent, patch, android, jel...     0.9999   \n",
       "297400  [lg, replacement, nearly, year, old, verizon, ...     0.9999   \n",
       "90019   [recently, began, working, let, get, right, aw...     0.9999   \n",
       "172930  [review, first, lumia, iphone, master, maps, m...     0.9999   \n",
       "124551  [stuck, droid, x, another, big, carrier, nearl...     0.9999   \n",
       "117725  [first, let, come, clean, currently, work, aut...     0.9999   \n",
       "107192  [years, heard, great, iphone, every, iteration...     0.9998   \n",
       "192513  [worst, thing, getting, amazing, phone, lack, ...     0.9998   \n",
       "107192  [years, heard, great, iphone, every, iteration...     0.9998   \n",
       "171787  [worst, thing, getting, amazing, phone, lack, ...     0.9998   \n",
       "\n",
       "       high_low_sentiment high_low_stars  \n",
       "188430               High           High  \n",
       "297400               High           High  \n",
       "90019                High           High  \n",
       "172930               High           High  \n",
       "124551               High           High  \n",
       "117725               High           High  \n",
       "107192               High        Neutral  \n",
       "192513               High           High  \n",
       "107192               High        Neutral  \n",
       "171787               High           High  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_reviews_tokenized['high_low_sentiment'] = amazon_reviews_tokenized['sentiment'].apply(lambda x: high_or_low_sentiment(x))\n",
    "amazon_reviews_tokenized['high_low_stars'] = amazon_reviews_tokenized['overall'].apply(lambda x: high_or_low_stars(x))\n",
    "\n",
    "amazon_reviews_tokenized.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_reviews_tokenized['is_accurate'] = amazon_reviews_tokenized['high_low_sentiment'] == amazon_reviews_tokenized['high_low_stars']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_reviews_tokenized['is_accurate'] = yelp_reviews_tokenized['high_low_sentiment'] == yelp_reviews_tokenized['high_low_stars']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>reviewTextCleaned</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>high_low_sentiment</th>\n",
       "      <th>high_low_stars</th>\n",
       "      <th>is_accurate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115777</th>\n",
       "      <td>1</td>\n",
       "      <td>I've been to the C &amp; B in Charleston, but last...</td>\n",
       "      <td>[c, b, charleston, last, night, first, time, n...</td>\n",
       "      <td>-0.9989</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80065</th>\n",
       "      <td>1</td>\n",
       "      <td>High prices, slow service, &amp; wrong orders.\\nNe...</td>\n",
       "      <td>[high, prices, slow, service, wrong, orders, n...</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42828</th>\n",
       "      <td>1</td>\n",
       "      <td>Awful. My advice is do not order from here. As...</td>\n",
       "      <td>[awful, advice, order, asked, well, done, pizz...</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257662</th>\n",
       "      <td>1</td>\n",
       "      <td>Stay away from Erin, I had a terrible experien...</td>\n",
       "      <td>[stay, away, erin, terrible, experience, know,...</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60585</th>\n",
       "      <td>1</td>\n",
       "      <td>Previous reviewer's description as a redneck j...</td>\n",
       "      <td>[previous, reviewer, description, redneck, joi...</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279146</th>\n",
       "      <td>1</td>\n",
       "      <td>Absolutely awful customer service. Had a 2:30 ...</td>\n",
       "      <td>[absolutely, awful, customer, service, reserva...</td>\n",
       "      <td>0.1874</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279146</th>\n",
       "      <td>1</td>\n",
       "      <td>Absolutely awful customer service. Had a 2:30 ...</td>\n",
       "      <td>[absolutely, awful, customer, service, reserva...</td>\n",
       "      <td>0.1874</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131505</th>\n",
       "      <td>1</td>\n",
       "      <td>The manager is very manipulative, We went to a...</td>\n",
       "      <td>[manager, manipulative, went, event, spoke, ba...</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52918</th>\n",
       "      <td>1</td>\n",
       "      <td>This store should be called knitter's nightmar...</td>\n",
       "      <td>[store, called, knitter, nightmare, went, purc...</td>\n",
       "      <td>0.5735</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232550</th>\n",
       "      <td>1</td>\n",
       "      <td>Overpriced Sysco food is about the only way to...</td>\n",
       "      <td>[overpriced, sysco, food, way, describe, serve...</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        stars                                  reviewTextCleaned  \\\n",
       "115777      1  I've been to the C & B in Charleston, but last...   \n",
       "80065       1  High prices, slow service, & wrong orders.\\nNe...   \n",
       "42828       1  Awful. My advice is do not order from here. As...   \n",
       "257662      1  Stay away from Erin, I had a terrible experien...   \n",
       "60585       1  Previous reviewer's description as a redneck j...   \n",
       "279146      1  Absolutely awful customer service. Had a 2:30 ...   \n",
       "279146      1  Absolutely awful customer service. Had a 2:30 ...   \n",
       "131505      1  The manager is very manipulative, We went to a...   \n",
       "52918       1  This store should be called knitter's nightmar...   \n",
       "232550      1  Overpriced Sysco food is about the only way to...   \n",
       "\n",
       "                                                tokenized  sentiment  \\\n",
       "115777  [c, b, charleston, last, night, first, time, n...    -0.9989   \n",
       "80065   [high, prices, slow, service, wrong, orders, n...    -0.4767   \n",
       "42828   [awful, advice, order, asked, well, done, pizz...    -0.4767   \n",
       "257662  [stay, away, erin, terrible, experience, know,...    -0.4767   \n",
       "60585   [previous, reviewer, description, redneck, joi...    -0.4767   \n",
       "279146  [absolutely, awful, customer, service, reserva...     0.1874   \n",
       "279146  [absolutely, awful, customer, service, reserva...     0.1874   \n",
       "131505  [manager, manipulative, went, event, spoke, ba...    -0.4767   \n",
       "52918   [store, called, knitter, nightmare, went, purc...     0.5735   \n",
       "232550  [overpriced, sysco, food, way, describe, serve...    -0.4767   \n",
       "\n",
       "       high_low_sentiment high_low_stars  is_accurate  \n",
       "115777                Low            Low         True  \n",
       "80065                 Low            Low         True  \n",
       "42828                 Low            Low         True  \n",
       "257662                Low            Low         True  \n",
       "60585                 Low            Low         True  \n",
       "279146            Neutral            Low        False  \n",
       "279146            Neutral            Low        False  \n",
       "131505                Low            Low         True  \n",
       "52918                High            Low        False  \n",
       "232550                Low            Low         True  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_reviews_tokenized.head(10)\n",
    "yelp_reviews_tokenized.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49.442, 48.947)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_accuracy = amazon_reviews_tokenized['is_accurate'].mean() * 100\n",
    "yelp_accuracy = yelp_reviews_tokenized['is_accurate'].mean() * 100\n",
    "\n",
    "amazon_accuracy, yelp_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 22:01:42.895680: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-17 22:01:42.895729: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-17 22:01:42.897137: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-17 22:01:43.039374: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 22:01:46.045215: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-17 22:01:46.068120: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-17 22:01:46.068163: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, GRU\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import Bidirectional, LSTM, Dense\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "all_tokens = [token for tokens in yelp_reviews_tokenized['tokenized'] for token in tokens]\n",
    "\n",
    "vocab_size = len(set(all_tokens))\n",
    "\n",
    "vocab_size += 1\n",
    "\n",
    "X = yelp_reviews_tokenized['tokenized']\n",
    "y = yelp_reviews_tokenized['high_low_stars']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train is a list of strings containing tokenized text\n",
    "# Create and fit a tokenizer on your tokenized text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert text to integer sequences\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_sequences = tokenizer.texts_to_sequences(X_val)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Step 1: Count word frequencies in your dataset\n",
    "word_counts = Counter(word for sentence in X_train_sequences for word in sentence)\n",
    "\n",
    "# Step 2: Determine a minimum word frequency threshold\n",
    "min_word_frequency = 5  # Adjust this threshold as needed\n",
    "\n",
    "# Step 3: Create a vocabulary list of words that meet the threshold\n",
    "vocabulary_list = [word for word, count in word_counts.items() if count >= min_word_frequency]\n",
    "\n",
    "vocabulary_list.append(\"<unknown>\")\n",
    "\n",
    "pruned_vocab_size = len(vocabulary_list)\n",
    "\n",
    "# Step 4: Create a mapping from words to integer indices\n",
    "word_to_index = {word: index for index, word in enumerate(vocabulary_list)}\n",
    "\n",
    "# Step 5: Replace words with indices in your data\n",
    "X_train_pruned = [[word_to_index.get(word, word_to_index[\"<unknown>\"]) for word in sentence] for sentence in X_train_sequences]\n",
    "\n",
    "\n",
    "# Find the maximum sequence length\n",
    "max_seq_length = max(len(seq) for seq in X_train_sequences)\n",
    "\n",
    "# Pad the sequences to a uniform length\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_seq_length, padding='post')\n",
    "X_val_padded = pad_sequences(X_val_sequences, maxlen=max_seq_length, padding='post')\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = to_categorical(label_encoder.fit_transform(y_train))\n",
    "y_val_encoded = to_categorical(label_encoder.transform(y_val))\n",
    "y_test_encoded = to_categorical(label_encoder.transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 22:02:02.799874: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-17 22:02:02.799965: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-17 22:02:02.799995: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-17 22:02:03.163420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-17 22:02:03.163484: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-17 22:02:03.163492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-01-17 22:02:03.163529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-17 22:02:03.163546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5578 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 22:02:04.935339: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 414120000 exceeds 10% of free system memory.\n",
      "2024-01-17 22:02:06.233134: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f12721f1be0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-17 22:02:06.233167: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-01-17 22:02:06.240866: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-17 22:02:06.262603: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-01-17 22:02:06.339312: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6563/6563 [==============================] - ETA: 0s - loss: 0.5238 - accuracy: 0.7873"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 22:04:07.602629: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 88740000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6563/6563 [==============================] - 128s 19ms/step - loss: 0.5238 - accuracy: 0.7873 - val_loss: 0.3938 - val_accuracy: 0.8539\n",
      "Epoch 2/10\n",
      "6563/6563 [==============================] - 62s 9ms/step - loss: 0.2397 - accuracy: 0.9168 - val_loss: 0.3483 - val_accuracy: 0.8818\n",
      "Epoch 3/10\n",
      "6563/6563 [==============================] - 59s 9ms/step - loss: 0.1319 - accuracy: 0.9598 - val_loss: 0.3782 - val_accuracy: 0.8982\n",
      "Epoch 4/10\n",
      "6563/6563 [==============================] - 57s 9ms/step - loss: 0.0869 - accuracy: 0.9761 - val_loss: 0.3861 - val_accuracy: 0.8999\n",
      "Epoch 5/10\n",
      "6563/6563 [==============================] - 57s 9ms/step - loss: 0.0603 - accuracy: 0.9831 - val_loss: 0.4262 - val_accuracy: 0.8915\n",
      "Epoch 6/10\n",
      "6563/6563 [==============================] - 56s 9ms/step - loss: 0.0551 - accuracy: 0.9857 - val_loss: 0.4328 - val_accuracy: 0.9005\n",
      "Epoch 7/10\n",
      "6563/6563 [==============================] - 57s 9ms/step - loss: 0.0512 - accuracy: 0.9888 - val_loss: 0.4938 - val_accuracy: 0.9057\n",
      "Epoch 8/10\n",
      "6563/6563 [==============================] - 56s 9ms/step - loss: 0.0390 - accuracy: 0.9915 - val_loss: 0.5429 - val_accuracy: 0.9067\n",
      "Epoch 9/10\n",
      "6563/6563 [==============================] - 57s 9ms/step - loss: 0.0328 - accuracy: 0.9926 - val_loss: 0.6571 - val_accuracy: 0.9002\n",
      "Epoch 10/10\n",
      "6563/6563 [==============================] - 57s 9ms/step - loss: 0.0304 - accuracy: 0.9934 - val_loss: 0.6405 - val_accuracy: 0.9054\n",
      "  22/1407 [..............................] - ETA: 6s - loss: 0.6797 - accuracy: 0.8949"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 22:12:52.180985: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 88740000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.6421 - accuracy: 0.9044\n",
      "Test Accuracy: 0.9044444561004639\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "#increase later\n",
    "embedding_dim = 100\n",
    "\n",
    "custom_learning_rate = 0.005\n",
    "\n",
    "custom_optimizer = Adam(learning_rate = custom_learning_rate)\n",
    "\n",
    "#switch to lstm?\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=pruned_vocab_size, output_dim=embedding_dim, input_length=max_seq_length))\n",
    "model.add(Flatten())\n",
    "\n",
    "#model.add(LSTM(128, dropout=0.2, return_sequences = True, recurrent_dropout=0, kernel_regularizer=l2(0.01)))\n",
    "#model.add(LSTM(64, dropout=0.2, return_sequences = True, recurrent_dropout=0, kernel_regularizer=l2(0.01)))\n",
    "#model.add(LSTM(32, dropout=0.2, recurrent_dropout=0, kernel_regularizer=l2(0.01)))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))  # You can adjust the number of units\n",
    "model.add(Dense(64, activation='relu'))   # You can adjust the number of units\n",
    "model.add(Dense(32, activation='relu'))   # You can adjust the number of units\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "#use sentiment scores?\n",
    "model.compile(loss='categorical_crossentropy', optimizer=custom_optimizer, metrics=['accuracy'])\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 32 \n",
    "history = model.fit(X_train_padded, y_train_encoded, validation_data=(X_val_padded, y_val_encoded), epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_padded, y_test_encoded)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
